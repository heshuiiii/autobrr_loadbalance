#!/usr/bin/env python3
"""
qBittorrent Load Balancer
ç›‘æ§torrentæ–‡ä»¶å¹¶æ™ºèƒ½åˆ†é…åˆ°å¤šä¸ªqBittorrentå®ä¾‹
æ”¯æŒä» Hetzner ç›‘æ§æ¥æ”¶ IP å˜æ›´é€šçŸ¥å¹¶è‡ªåŠ¨æ›´æ–°é…ç½®
"""

import json
import os
import time
import threading
import logging
import csv
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from dataclasses import dataclass, field
import hashlib
from pathlib import Path
import qbittorrentapi
from flask import Flask, request, jsonify
from webhook_server import WebhookServer


# é…ç½®å¸¸é‡
DEFAULT_CONFIG_FILE = "config.json"

# æ—¶é—´é—´éš”å¸¸é‡ï¼ˆç§’ï¼‰
DEFAULT_SLEEP_TIME = 1
TASK_PROCESSOR_SLEEP = 1
ERROR_RETRY_SLEEP = 5
RECONNECT_INTERVAL = 180
CONNECTION_TIMEOUT = 10

# ç½‘ç»œå’Œå­˜å‚¨å¸¸é‡
BYTES_TO_KB = 1024
BYTES_TO_GB = 1024 ** 3
BYTES_TO_TB = 1024 ** 4
MAX_RECONNECT_ATTEMPTS = 1

# ç§å­æ±‡æŠ¥ç›¸å…³å¸¸é‡
ANNOUNCE_WINDOW_TOLERANCE = 5

# æ”¯æŒçš„æ’åºé”®ï¼ˆæ‰€æœ‰å‡ä¸ºå°å€¼ä¼˜å…ˆï¼‰
SUPPORTED_SORT_KEYS = {
    'upload_speed': 'ä¸Šä¼ é€Ÿåº¦',
    'download_speed': 'ä¸‹è½½é€Ÿåº¦',
    'active_downloads': 'æ´»è·ƒä¸‹è½½æ•°'
}
DEFAULT_PRIMARY_SORT_KEY = 'upload_speed'

# åˆ›å»ºä¸€ä¸ªç®€å•çš„loggerï¼Œé¿å…åœ¨åˆå§‹åŒ–ä¹‹å‰è¾“å‡ºæ—¥å¿—
logger = logging.getLogger(__name__)

def setup_logging(log_dir=None):
    """è®¾ç½®æ—¥å¿—é…ç½®ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""
    # åˆå§‹åŒ–logger
    root_logger = logging.getLogger()
    root_logger.handlers.clear()
    
    app_logger = logging.getLogger(__name__)
    app_logger.setLevel(logging.DEBUG)
    app_logger.handlers.clear()
    
    # è®¾ç½®åŸºç¡€æ ¼å¼
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨
    _add_console_handler(app_logger, formatter)
    
    # æ·»åŠ æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¦‚æœæŒ‡å®šäº†æ—¥å¿—ç›®å½•ï¼‰
    if log_dir:
        _add_file_handlers(app_logger, formatter, log_dir)
    
    return app_logger


def _add_console_handler(logger, formatter):
    """æ·»åŠ æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨"""
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)


def _add_file_handlers(logger, formatter, log_dir):
    """æ·»åŠ æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨"""
    try:
        from logging.handlers import TimedRotatingFileHandler
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(log_dir, exist_ok=True)
        
        # ä¸»æ—¥å¿—æ–‡ä»¶
        main_log_path = os.path.join(log_dir, 'qbittorrent_loadbalancer.log')
        file_handler = _create_rotating_handler(main_log_path, logging.DEBUG, formatter)
        logger.addHandler(file_handler)
        
        # é”™è¯¯æ—¥å¿—æ–‡ä»¶
        error_log_path = os.path.join(log_dir, 'qbittorrent_error.log')
        error_handler = _create_rotating_handler(error_log_path, logging.ERROR, formatter)
        logger.addHandler(error_handler)
        
        logger.info(f"æ—¥å¿—æ–‡ä»¶å°†ä¿å­˜åˆ°ï¼š{log_dir}")
        
    except Exception as e:
        print(f"è­¦å‘Š: æ— æ³•è®¾ç½®æ–‡ä»¶æ—¥å¿—: {e}")


def _create_rotating_handler(filename, level, formatter):
    """åˆ›å»ºæŒ‰æ—¥æœŸè½®è½¬çš„æ—¥å¿—å¤„ç†å™¨"""
    from logging.handlers import TimedRotatingFileHandler
    
    handler = TimedRotatingFileHandler(
        filename=filename,
        when='midnight',
        interval=1,
        backupCount=7,
        encoding='utf-8'
    )
    handler.setLevel(level)
    handler.setFormatter(formatter)
    return handler


@dataclass
class InstanceInfo:
    """qBittorrentå®ä¾‹ä¿¡æ¯"""
    name: str
    url: str
    username: str
    password: str
    client: Optional[qbittorrentapi.Client] = None
    is_connected: bool = False
    upload_speed: float = 0.0  # KB/s
    download_speed: float = 0.0  # KB/s
    active_downloads: int = 0
    free_space: int = 0  # bytes
    new_tasks_count: int = 0  # æ–°åˆ†é…çš„ä»»åŠ¡æ•°
    total_added_tasks_count: int = 0  # å·²æ·»åŠ çš„æ€»ä»»åŠ¡è®¡æ•°
    success_metrics_count: int = 0  # æˆåŠŸè·å–ç»Ÿè®¡ä¿¡æ¯çš„æ¬¡æ•°
    traffic_out: int = 0  # å‡ºç«™æµé‡ (bytes)
    traffic_limit: int = 0  # æµé‡é™åˆ¶ (bytes)
    traffic_check_url: str = ""  # æµé‡æ£€æŸ¥URL
    reserved_space: int = 0  # éœ€è¦ä¿ç•™çš„ç©ºé—²ç©ºé—´ (bytes)
    last_update: datetime = field(default_factory=datetime.now)
    is_reconnecting: bool = False  # æ˜¯å¦æ­£åœ¨é‡è¿ä¸­


@dataclass
class PendingTorrent:
    """å¾…å¤„ç†çš„torrent"""
    download_url: str
    release_name: str
    category: Optional[str] = None


class ConfigManager:
    """ğŸ†• é…ç½®æ–‡ä»¶ç®¡ç†å™¨ - è´Ÿè´£è¯»å–å’Œæ›´æ–° config.json"""
    def __init__(self, config_file: str = DEFAULT_CONFIG_FILE):
        self.config_file = config_file
        self.config_lock = threading.Lock()
    
    def load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{self.config_file}")
            raise
        except json.JSONDecodeError:
            logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼š{self.config_file}")
            raise
    
    def save_config(self, config: dict) -> bool:
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        try:
            with self.config_lock:
                # å…ˆå¤‡ä»½åŸé…ç½®
                backup_file = f"{self.config_file}.backup"
                if os.path.exists(self.config_file):
                    import shutil
                    shutil.copy2(self.config_file, backup_file)
                
                # å†™å…¥æ–°é…ç½®
                with open(self.config_file, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                
                logger.info(f"âœ“ é…ç½®æ–‡ä»¶å·²æ›´æ–°ï¼š{self.config_file}")
                return True
                
        except Exception as e:
            logger.error(f"âœ— ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥ï¼š{e}")
            return False
    
    def extract_ip_from_url(self, url: str) -> Optional[str]:
        """
        ä» URL ä¸­æå– IP åœ°å€æˆ–ä¸»æœºå
        æ”¯æŒå¤šç§æ ¼å¼ï¼š
        - http://46.224.213.76:9090 â†’ 46.224.213.76
        - http://111:9090 â†’ 111
        - http://localhost:9090 â†’ localhost
        - http://qb-server:9090 â†’ qb-server
        """
        import re
        
        # æ–¹æ³•1: å°è¯•åŒ¹é…å®Œæ•´ IPv4 åœ°å€
        ipv4_pattern = r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'
        match = re.search(ipv4_pattern, url)
        if match:
            return match.group(1)
        
        # æ–¹æ³•2: æå– host:port æ ¼å¼ä¸­çš„ host éƒ¨åˆ†
        # åŒ¹é… http(s)://host:port æˆ– http(s)://host
        host_pattern = r'https?://([^:/]+)'
        match = re.search(host_pattern, url)
        if match:
            return match.group(1)
        
        logger.warning(f"æ— æ³•ä» URL ä¸­æå– IP/ä¸»æœºå: {url}")
        return None
    
    def update_instance_ip(self, old_ip: str, new_ip: str) -> Dict[str, any]:
        """
        ğŸ†• ä¼˜åŒ–ç‰ˆIPæ›´æ–°é€»è¾‘ï¼š
        1. å¦‚æœåªæä¾›new_ipï¼ˆåˆå§‹åˆ›å»ºåœºæ™¯ï¼‰ï¼Œæ‰¾ç¬¬ä¸€ä¸ªå ä½ç¬¦å®ä¾‹æ›´æ–°
        2. å¦‚æœæä¾›old_ipå’Œnew_ipï¼Œæ‰§è¡Œæ›¿æ¢
        3. å¦‚æœnew_ipå·²å­˜åœ¨ï¼Œè·³è¿‡
        """
        try:
            config = self.load_config()
            instances = config.get('qbittorrent_instances', [])
            
            # 1. æ£€æŸ¥ new_ip æ˜¯å¦å·²å­˜åœ¨
            for instance in instances:
                current_host = self.extract_ip_from_url(instance.get('url', ''))
                if current_host == new_ip:
                    logger.info(f"â„¹ IP {new_ip} å·²å­˜åœ¨äºå®ä¾‹ {instance.get('name')} ä¸­")
                    return {'success': True, 'updated_count': 0, 'message': f'IP {new_ip} å·²å­˜åœ¨'}
            
            # 2. ç¡®å®šè¦æ›´æ–°çš„ç›®æ ‡å®ä¾‹
            target_instance = None
            
            # å¦‚æœæä¾›äº†old_ipï¼Œä¼˜å…ˆåŒ¹é…old_ip
            if old_ip:
                for instance in instances:
                    current_host = self.extract_ip_from_url(instance.get('url', ''))
                    if current_host == old_ip:
                        target_instance = instance
                        logger.info(f"ğŸ¯ åŒ¹é…åˆ°æ—§IP ({old_ip}) çš„å®ä¾‹: {instance.get('name')}")
                        break
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°old_ipï¼Œæˆ–è€…æ²¡æœ‰æä¾›old_ipï¼ˆåˆå§‹åˆ›å»ºåœºæ™¯ï¼‰
            if not target_instance:
                # æ”¶é›†æ‰€æœ‰å½“å‰æœ‰æ•ˆçš„IP
                current_ips = set()
                for inst in instances:
                    ip = self.extract_ip_from_url(inst.get('url', ''))
                    if ip and self._is_valid_ip(ip):
                        current_ips.add(ip)
                
                # æ‰¾ç¬¬ä¸€ä¸ªä½¿ç”¨å ä½ç¬¦æˆ–æ— æ•ˆIPçš„å®ä¾‹
                for instance in instances:
                    current_host = self.extract_ip_from_url(instance.get('url', ''))
                    if not current_host or not self._is_valid_ip(current_host):
                        target_instance = instance
                        logger.info(f"ğŸ“ æ‰¾åˆ°å ä½ç¬¦å®ä¾‹è¿›è¡Œæ›´æ–°: {instance.get('name')}")
                        break
            
            # 3. æ‰§è¡Œæ›´æ–°
            if target_instance:
                old_url = target_instance['url']
                current_host = self.extract_ip_from_url(old_url)
                
                if current_host:
                    new_url = old_url.replace(current_host, new_ip)
                else:
                    # å¦‚æœæ— æ³•æå–hostï¼Œé‡æ„URL
                    import re
                    port_match = re.search(r':(\d+)', old_url)
                    port = port_match.group(1) if port_match else '9090'
                    new_url = f"http://{new_ip}:{port}"
                
                target_instance['url'] = new_url
                
                if self.save_config(config):
                    logger.info(f"âœ… å·²æ›´æ–°å®ä¾‹ {target_instance.get('name')}: {old_url} â†’ {new_url}")
                    return {
                        'success': True,
                        'updated_count': 1,
                        'updated_instances': [{
                            'name': target_instance.get('name'),
                            'old_url': old_url,
                            'new_url': new_url
                        }],
                        'message': f'æˆåŠŸæ›´æ–°åˆ° {new_ip}'
                    }
            
            logger.warning("âš  æœªæ‰¾åˆ°åˆé€‚çš„å®ä¾‹è¿›è¡Œæ›´æ–°")
            return {'success': True, 'updated_count': 0, 'message': 'æœªæ‰¾åˆ°åˆé€‚çš„æ›´æ–°ç›®æ ‡'}
                
        except Exception as e:
            logger.error(f"âœ— æ›´æ–°å®ä¾‹IPå¤±è´¥ï¼š{e}")
            return {'success': False, 'error': str(e)}

    def _is_valid_ip(self, ip: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„IPv4åœ°å€"""
        import re
        pattern = r'^(\d{1,3}\.){3}\d{1,3}$'
        if not re.match(pattern, ip):
            return False
        # éªŒè¯æ¯ä¸ªæ•°å­—åœ¨0-255èŒƒå›´å†…
        parts = ip.split('.')
        return all(0 <= int(part) <= 255 for part in parts)
    
    def check_ip_exists(self, ip: str) -> bool:
        """æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šIP"""
        try:
            config = self.load_config()
            instances = config.get('qbittorrent_instances', [])
            
            for instance in instances:
                url = instance.get('url', '')
                # ä½¿ç”¨å¢å¼ºçš„æå–æ–¹æ³•
                current_host = self.extract_ip_from_url(url)
                if current_host == ip or ip in url:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥IPå­˜åœ¨æ€§å¤±è´¥ï¼š{e}")
            return False


class ConfigWatcher:
    """é…ç½®æ–‡ä»¶ç›‘æ§å™¨ - æ£€æµ‹ config.json å˜åŒ–å¹¶è§¦å‘çƒ­é‡è½½"""
    
    def __init__(self, config_file: str, check_interval: int = 5):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        self.config_file = Path(config_file)
        self.check_interval = check_interval
        self.last_hash = self._get_file_hash()
        self.callbacks = []
        self.running = False
        self.watch_thread = None
        
    def _get_file_hash(self) -> str:
        """è®¡ç®—é…ç½®æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
        try:
            if not self.config_file.exists():
                return ""
            
            with open(self.config_file, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: {e}")
            return ""
    
    def register_callback(self, callback):
        """æ³¨å†Œé…ç½®å˜åŒ–æ—¶çš„å›è°ƒå‡½æ•°"""
        self.callbacks.append(callback)
        logger.debug(f"å·²æ³¨å†Œé…ç½®å˜åŒ–å›è°ƒ: {callback.__name__}")
    
    def _notify_change(self):
        """é€šçŸ¥æ‰€æœ‰å›è°ƒå‡½æ•°é…ç½®å·²å˜åŒ–"""
        logger.info(f"ğŸ”¥ æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜åŒ–ï¼Œè§¦å‘ {len(self.callbacks)} ä¸ªå›è°ƒ")
        for callback in self.callbacks:
            try:
                callback()
            except Exception as e:
                logger.error(f"æ‰§è¡Œå›è°ƒå¤±è´¥: {callback.__name__}, é”™è¯¯: {e}")
    
    def _watch_loop(self):
        """ç›‘æ§å¾ªç¯"""
        logger.info(f"ğŸ“‚ é…ç½®æ–‡ä»¶ç›‘æ§å·²å¯åŠ¨ï¼Œæ£€æŸ¥é—´éš”: {self.check_interval}ç§’")
        
        while self.running:
            try:
                current_hash = self._get_file_hash()
                
                if current_hash and current_hash != self.last_hash:
                    logger.info(f"ğŸ”” é…ç½®æ–‡ä»¶å·²æ›´æ–°: {self.config_file}")
                    self.last_hash = current_hash
                    time.sleep(0.5)  # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
                    self._notify_change()
                
                time.sleep(self.check_interval)
                
            except Exception as e:
                logger.error(f"é…ç½®ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(self.check_interval)
    
    def start(self):
        """å¯åŠ¨ç›‘æ§"""
        if self.running:
            logger.warning("é…ç½®ç›‘æ§å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.running = True
        self.watch_thread = threading.Thread(
            target=self._watch_loop,
            daemon=True,
            name="config-watcher"
        )
        self.watch_thread.start()
        logger.info("âœ“ é…ç½®æ–‡ä»¶ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        if self.watch_thread:
            self.watch_thread.join(timeout=2)
        logger.info("é…ç½®æ–‡ä»¶ç›‘æ§å·²åœæ­¢")


class QBittorrentLoadBalancer:
    """qBittorrentè´Ÿè½½å‡è¡¡å™¨"""
    
    def __init__(self, config_file: str = DEFAULT_CONFIG_FILE):
        self.config_manager = ConfigManager(config_file)
        self.config = self.config_manager.load_config()
        self.instances: List[InstanceInfo] = []
        self.pending_torrents: List[PendingTorrent] = []
        self.pending_torrents_lock = threading.Lock()
        self.instances_lock = threading.Lock()
        self.announce_retry_counts = {}
        
        # é‡æ–°é…ç½®æ—¥å¿—
        self._setup_logging()
        
        # åˆå§‹åŒ–webhookæœåŠ¡å™¨
        self.webhook_server: Optional[WebhookServer] = None
        
        # åˆå§‹åŒ– Flask API æœåŠ¡å™¨
        self.api_server: Optional[Flask] = None
        self.api_port = self.config.get('api_port', 5007)
        
        # ğŸ†• åˆå§‹åŒ–é…ç½®æ–‡ä»¶ç›‘æ§å™¨
        self.config_watcher = ConfigWatcher(
            config_file=config_file,
            check_interval=self.config.get('config_watch_interval', 5)
        )
        # æ³¨å†Œé…ç½®å˜åŒ–æ—¶çš„å›è°ƒ
        self.config_watcher.register_callback(self._on_config_changed)
        
        self._setup_environment()
        
    def _setup_logging(self) -> None:
        """æ ¹æ®é…ç½®è®¾ç½®æ—¥å¿—"""
        global logger
        
        # ä»é…ç½®ä¸­è·å–æ—¥å¿—ç›®å½•ï¼Œé»˜è®¤ä¸º /app/logsï¼ˆDockerç¯å¢ƒï¼‰æˆ– ./logsï¼ˆæœ¬åœ°ç¯å¢ƒï¼‰
        log_dir = self.config.get('log_dir')
        if log_dir is None:
            # è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒ
            if os.path.exists('/app'):  # Dockerç¯å¢ƒ
                log_dir = '/app/logs'
            else:  # æœ¬åœ°ç¯å¢ƒ
                log_dir = './logs'
        
        logger = setup_logging(log_dir)
        
    def _setup_environment(self) -> None:
        """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
        # éªŒè¯é…ç½®
        self._validate_config()
        # è®¾ç½®é…ç½®é»˜è®¤å€¼å’ŒéªŒè¯
        self._set_config_defaults()
        
        # ğŸ†• ä¼˜å…ˆå¯åŠ¨ API æœåŠ¡å™¨å’Œ Webhook æœåŠ¡å™¨ï¼ˆç«‹å³å¯ç”¨ï¼‰
        self._start_api_server()
        self._start_webhook_server()
        
        # å¼‚æ­¥åˆå§‹åŒ– qBittorrent å®ä¾‹ï¼ˆä¸é˜»å¡å¯åŠ¨ï¼‰
        self._init_instances_async()
    def _on_config_changed(self):
        """é…ç½®æ–‡ä»¶å˜åŒ–æ—¶çš„å¤„ç†å‡½æ•°ï¼ˆçƒ­é‡è½½æ ¸å¿ƒé€»è¾‘ï¼‰"""
        logger.info("="*70)
        logger.info("ğŸ”¥ å¼€å§‹çƒ­é‡è½½é…ç½®...")
        logger.info("="*70)
        
        try:
            # 1. é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
            new_config = self.config_manager.load_config()
            logger.info("âœ“ é…ç½®æ–‡ä»¶å·²é‡æ–°è¯»å–")
            
            # 2. æ¯”å¯¹å®ä¾‹é…ç½®çš„å˜åŒ–
            old_instances = {inst['name']: inst for inst in self.config.get('qbittorrent_instances', [])}
            new_instances = {inst['name']: inst for inst in new_config.get('qbittorrent_instances', [])}
            
            # 3. æ›´æ–°å†…å­˜ä¸­çš„å®ä¾‹é…ç½®
            instances_changed = False
            with self.instances_lock:
                for instance in self.instances:
                    if instance.name in new_instances:
                        new_conf = new_instances[instance.name]
                        old_conf = old_instances.get(instance.name, {})
                        
                        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šæ¯”å¯¹æ–°é…ç½®å’Œå†…å­˜ä¸­çš„å®ä¾‹URLï¼ˆè€Œä¸æ˜¯æ—§é…ç½®ï¼‰
                        if new_conf['url'] != instance.url:
                            old_url = instance.url
                            instance.url = new_conf['url']
                            instance.username = new_conf['username']
                            instance.password = new_conf['password']
                            instance.is_connected = False
                            instances_changed = True
                            
                            logger.info(f"ğŸ”„ å®ä¾‹ {instance.name} URL å·²å˜æ›´:")
                            logger.info(f"   æ—§: {old_url}")
                            logger.info(f"   æ–°: {instance.url}")
                            
                            # ç«‹å³è§¦å‘é‡è¿
                            self._async_reconnect_single_instance(instance)
                        
                        # æ£€æŸ¥è®¤è¯ä¿¡æ¯æ˜¯å¦å˜åŒ–
                        elif (new_conf.get('username') != instance.username or
                            new_conf.get('password') != instance.password):
                            instance.username = new_conf['username']
                            instance.password = new_conf['password']
                            instance.is_connected = False
                            instances_changed = True
                            logger.info(f"ğŸ”‘ å®ä¾‹ {instance.name} è®¤è¯ä¿¡æ¯å·²å˜æ›´ï¼Œè§¦å‘é‡è¿")
                            self._async_reconnect_single_instance(instance)
                        else:
                            logger.debug(f"âœ“ å®ä¾‹ {instance.name} é…ç½®æ— å˜åŒ–")
            
            # 4. æ›´æ–°å…¨å±€é…ç½®
            self.config = new_config
            logger.info("âœ“ å…¨å±€é…ç½®å·²æ›´æ–°")
            
            if not instances_changed:
                logger.info("â„¹ï¸  æœ¬æ¬¡é…ç½®å˜æ›´æœªæ¶‰åŠå®ä¾‹URLæˆ–è®¤è¯ä¿¡æ¯")
            
            logger.info("="*70)
            logger.info("ğŸ‰ é…ç½®çƒ­é‡è½½å®Œæˆ")
            logger.info("="*70)
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®çƒ­é‡è½½å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())


    def _async_reconnect_single_instance(self, instance: InstanceInfo):
        """å¼‚æ­¥é‡è¿å•ä¸ªå®ä¾‹ï¼ˆä¸é˜»å¡ä¸»çº¿ç¨‹ï¼‰"""
        def reconnect():
            time.sleep(1)  # ç­‰å¾…1ç§’ç¡®ä¿é…ç½®ç¨³å®š
            logger.info(f"ğŸ”Œ å¼€å§‹é‡è¿å®ä¾‹: {instance.name}")
            self._connect_instance(instance)
        
        threading.Thread(
            target=reconnect,
            daemon=True,
            name=f"reconnect-{instance.name}"
        ).start()


    def _validate_config(self) -> None:
        """éªŒè¯é…ç½®æ–‡ä»¶çš„æœ‰æ•ˆæ€§"""
        # éªŒè¯primary_sort_keyé…ç½®
        primary_sort_key = self.config.get('primary_sort_key', DEFAULT_PRIMARY_SORT_KEY)
        if primary_sort_key not in SUPPORTED_SORT_KEYS:
            logger.warning(f"ä¸æ”¯æŒçš„æ’åºé”®ï¼š{primary_sort_key}ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼š{DEFAULT_PRIMARY_SORT_KEY}")
            self.config['primary_sort_key'] = DEFAULT_PRIMARY_SORT_KEY
        else:
            logger.info(f"ä½¿ç”¨æ’åºç­–ç•¥ï¼šä¸»è¦å› ç´ ={SUPPORTED_SORT_KEYS[primary_sort_key]}ï¼Œæ¬¡è¦å› ç´ =ç´¯è®¡æ·»åŠ ä»»åŠ¡æ•°ï¼Œç¬¬ä¸‰å› ç´ =ç©ºé—²ç©ºé—´")
            
        # éªŒè¯å¿«é€Ÿæ±‡æŠ¥åˆ†ç±»é»‘åå•é…ç½®
        blacklist = self.config.get('fast_announce_category_blacklist')
        if blacklist is not None:
            if not isinstance(blacklist, list):
                logger.warning(f"fast_announce_category_blacklist é…ç½®æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»æ˜¯æ•°ç»„ï¼Œå½“å‰ç±»å‹ï¼š{type(blacklist)}ï¼Œå·²é‡ç½®ä¸ºç©ºæ•°ç»„")
                self.config['fast_announce_category_blacklist'] = []
            else:
                # éªŒè¯æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å­—ç¬¦ä¸²
                valid_blacklist = []
                for item in blacklist:
                    if isinstance(item, str):
                        valid_blacklist.append(item)
                    else:
                        logger.warning(f"é»‘åå•ä¸­åŒ…å«éå­—ç¬¦ä¸²é¡¹ç›®ï¼š{item} (ç±»å‹ï¼š{type(item)})ï¼Œå·²å¿½ç•¥")
                
                self.config['fast_announce_category_blacklist'] = valid_blacklist
                if valid_blacklist:
                    logger.info(f"å¿«é€Ÿæ±‡æŠ¥åˆ†ç±»é»‘åå•å·²é…ç½®ï¼ŒåŒ…å« {len(valid_blacklist)} ä¸ªåˆ†ç±»ï¼š{valid_blacklist}")
                else:
                    logger.info("å¿«é€Ÿæ±‡æŠ¥åˆ†ç±»é»‘åå•ä¸ºç©ºï¼Œæ‰€æœ‰åˆ†ç±»éƒ½å°†æ‰§è¡Œå¿«é€Ÿæ±‡æŠ¥")
        else:
            # å¦‚æœæ²¡æœ‰é…ç½®é»‘åå•ï¼Œè®¾ç½®ä¸ºç©ºæ•°ç»„
            self.config['fast_announce_category_blacklist'] = []
            logger.info("æœªé…ç½®å¿«é€Ÿæ±‡æŠ¥åˆ†ç±»é»‘åå•ï¼Œæ‰€æœ‰åˆ†ç±»éƒ½å°†æ‰§è¡Œå¿«é€Ÿæ±‡æŠ¥")
            
    def _load_config(self, config_file: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆå·²è¢« ConfigManager æ›¿ä»£ï¼‰"""
        return self.config_manager.load_config()
    
    def _set_config_defaults(self) -> None:
        """è®¾ç½®é…ç½®é»˜è®¤å€¼å’ŒéªŒè¯"""
        # è®¾ç½®å¿«é€Ÿæ±‡æŠ¥é—´éš”é»˜è®¤å€¼ï¼Œå¹¶é™åˆ¶åœ¨2-10ç§’èŒƒå›´å†…
        fast_interval = self.config.get('fast_announce_interval', 3)
        if not isinstance(fast_interval, (int, float)) or fast_interval < 2 or fast_interval > 10:
            logger.warning(f"fast_announce_interval å€¼æ— æ•ˆ ({fast_interval})ï¼Œå¿…é¡»åœ¨2-10ç§’èŒƒå›´å†…ï¼Œä½¿ç”¨é»˜è®¤å€¼4ç§’")
            fast_interval = 3
        self.config['fast_announce_interval'] = fast_interval
        
        logger.info(f"çŠ¶æ€æ›´æ–°é—´éš”é…ç½®ï¼šå¿«é€Ÿæ£€æŸ¥={fast_interval}ç§’ï¼Œæ­£å¸¸æ£€æŸ¥={fast_interval * 2}ç§’")

    def _init_instances(self) -> None:
        """åˆå§‹åŒ–qBittorrentå®ä¾‹è¿æ¥ï¼ˆåŒæ­¥ç‰ˆæœ¬ - ä¼šé˜»å¡ï¼‰"""
        for instance_config in self.config['qbittorrent_instances']:
            instance = self._create_instance_from_config(instance_config)
            self._connect_instance(instance)
            self.instances.append(instance)
    
    def _init_instances_async(self) -> None:
        """ğŸ†• å¼‚æ­¥åˆå§‹åŒ–qBittorrentå®ä¾‹è¿æ¥ï¼ˆä¸é˜»å¡å¯åŠ¨ï¼‰"""
        logger.info("ğŸ”„ å¼€å§‹å¼‚æ­¥åˆå§‹åŒ– qBittorrent å®ä¾‹...")
        
        # å…ˆåˆ›å»ºæ‰€æœ‰å®ä¾‹å¯¹è±¡ï¼ˆä¸è¿æ¥ï¼‰
        for instance_config in self.config['qbittorrent_instances']:
            instance = self._create_instance_from_config(instance_config)
            instance.is_connected = False
            self.instances.append(instance)
            logger.info(f"ğŸ“ å·²åŠ è½½å®ä¾‹é…ç½®: {instance.name} ({instance.url})")
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿æ¥å®ä¾‹
        def connect_instances():
            logger.info("ğŸ”Œ å¼€å§‹è¿æ¥ qBittorrent å®ä¾‹...")
            for instance in self.instances:
                self._connect_instance(instance)
            logger.info("âœ… qBittorrent å®ä¾‹åˆå§‹åŒ–å®Œæˆ")
        
        connect_thread = threading.Thread(target=connect_instances, daemon=True, name="init-instances")
        connect_thread.start()
            
    def _create_instance_from_config(self, config: Dict[str, str]) -> InstanceInfo:
        """æ ¹æ®é…ç½®åˆ›å»ºå®ä¾‹ä¿¡æ¯å¯¹è±¡"""
        # å®‰å…¨åœ°è½¬æ¢æµé‡é™åˆ¶å€¼ï¼ˆä»MBè½¬æ¢ä¸ºå­—èŠ‚ï¼‰
        try:
            traffic_limit_mb = config.get('traffic_limit', 0.0)
            traffic_limit_bytes = int(float(traffic_limit_mb) * 1024 * 1024)  # MBè½¬å­—èŠ‚
        except (ValueError, TypeError) as e:
            logger.warning(f"å®ä¾‹ {config.get('name', 'Unknown')} æµé‡é™åˆ¶å€¼è½¬æ¢å¤±è´¥ï¼š{e}ï¼Œè®¾ç½®ä¸º0")
            traffic_limit_bytes = 0
        
        # å®‰å…¨åœ°è½¬æ¢ä¿ç•™ç©ºé—´å€¼ï¼ˆä»MBè½¬æ¢ä¸ºå­—èŠ‚ï¼‰
        try:
            reserved_space_mb = config.get('reserved_space', 21 * 1024)  # é»˜è®¤21GB
            reserved_space_bytes = int(float(reserved_space_mb) * 1024 * 1024)  # MBè½¬å­—èŠ‚
        except (ValueError, TypeError) as e:
            logger.warning(f"å®ä¾‹ {config.get('name', 'Unknown')} ä¿ç•™ç©ºé—´å€¼è½¬æ¢å¤±è´¥ï¼š{e}ï¼Œè®¾ç½®ä¸ºé»˜è®¤å€¼21GB")
            reserved_space_bytes = 21 * BYTES_TO_GB
            
        return InstanceInfo(
            name=config['name'],
            url=config['url'],
            username=config['username'],
            password=config['password'],
            traffic_check_url=config.get('traffic_check_url', ''),
            traffic_limit=traffic_limit_bytes,
            reserved_space=reserved_space_bytes
        )
        
    def _connect_instance(self, instance: InstanceInfo) -> None:
        """è¿æ¥åˆ°qBittorrentå®ä¾‹"""
        try:
            connection_timeout = self.config.get('connection_timeout', CONNECTION_TIMEOUT)
            client = qbittorrentapi.Client(
                host=instance.url,
                username=instance.username,
                password=instance.password,
                REQUESTS_ARGS={'timeout': connection_timeout}
            )
            client.auth_log_in()
            instance.client = client
            instance.is_connected = True
            logger.info(f"æˆåŠŸè¿æ¥åˆ°å®ä¾‹ï¼š{instance.name}")
        except Exception as e:
            logger.error(f"è¿æ¥å®ä¾‹å¤±è´¥ï¼š{instance.name}ï¼Œé”™è¯¯ï¼š{e}")
            instance.is_connected = False
            # è®°å½•è¿æ¥å¤±è´¥çš„æ—¶é—´ï¼Œç”¨äºåç»­é‡è¿åˆ¤æ–­
            instance.last_update = datetime.now()
            
    def _attempt_reconnect(self, instance: InstanceInfo) -> bool:
        """å°è¯•é‡æ–°è¿æ¥åˆ°å®ä¾‹"""
        logger.info(f"å°è¯•é‡æ–°è¿æ¥åˆ°å®ä¾‹ï¼š{instance.name}")
        
        max_attempts = self.config.get('max_reconnect_attempts', MAX_RECONNECT_ATTEMPTS)
        connection_timeout = self.config.get('connection_timeout', CONNECTION_TIMEOUT)
        
        for attempt in range(max_attempts):
            try:
                client = qbittorrentapi.Client(
                    host=instance.url,
                    username=instance.username,
                    password=instance.password,
                    REQUESTS_ARGS={'timeout': connection_timeout}
                )
                
                # è®¾ç½®è¿æ¥è¶…æ—¶å¹¶å°è¯•ç™»å½•
                client.auth_log_in()
                
                # æ›´æ–°å®ä¾‹çŠ¶æ€éœ€è¦åœ¨é”å†…è¿›è¡Œ
                with self.instances_lock:
                    instance.client = client
                    instance.is_connected = True
                    instance.is_reconnecting = False
                    
                logger.info(f"é‡æ–°è¿æ¥æˆåŠŸï¼š{instance.name}ï¼ˆå°è¯• {attempt + 1}/{max_attempts}ï¼‰")
                return True
                
            except Exception as e:
                logger.warning(f"é‡è¿å°è¯• {attempt + 1}/{max_attempts} å¤±è´¥ï¼š{instance.name}ï¼Œé”™è¯¯ï¼š{e}")
                if attempt < max_attempts - 1:
                    time.sleep(2)  # æ¯æ¬¡é‡è¿å°è¯•é—´ç­‰å¾…2ç§’
                    
        logger.error(f"é‡è¿å½»åº•å¤±è´¥ï¼š{instance.name}")
        
        # æ›´æ–°å¤±è´¥æ—¶é—´éœ€è¦åœ¨é”å†…è¿›è¡Œ
        with self.instances_lock:
            instance.last_update = datetime.now()
            instance.is_reconnecting = False
            
        return False
        
    def _async_reconnect_instance(self, instance: InstanceInfo) -> None:
        """å¼‚æ­¥é‡è¿å•ä¸ªå®ä¾‹ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰"""
        try:
            self._attempt_reconnect(instance)
        except Exception as e:
            logger.error(f"å¼‚æ­¥é‡è¿è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸ï¼š{instance.name}ï¼Œé”™è¯¯ï¼š{e}")
            with self.instances_lock:
                instance.last_update = datetime.now()
                instance.is_reconnecting = False
        
    def _check_and_schedule_reconnects(self) -> None:
        """æ£€æŸ¥æ–­å¼€çš„å®ä¾‹å¹¶è°ƒåº¦é‡è¿ï¼ˆéé˜»å¡ï¼‰"""
        current_time = datetime.now()
        reconnect_interval = self.config.get('reconnect_interval', RECONNECT_INTERVAL)
        
        instances_to_reconnect = []
        
        with self.instances_lock:
            for instance in self.instances:
                # åªå¤„ç†æœªè¿æ¥ä¸”æœªåœ¨é‡è¿ä¸­çš„å®ä¾‹
                if not instance.is_connected and not instance.is_reconnecting:
                    # æ£€æŸ¥æ˜¯å¦åˆ°äº†é‡è¿æ—¶é—´
                    time_since_last_attempt = (current_time - instance.last_update).total_seconds()
                    if time_since_last_attempt >= reconnect_interval:
                        instances_to_reconnect.append(instance)
                        # æ ‡è®°ä¸ºæ­£åœ¨é‡è¿ï¼Œé˜²æ­¢é‡å¤è°ƒåº¦
                        instance.is_reconnecting = True
                        instance.last_update = current_time
                        
        # åœ¨é”å¤–å¯åŠ¨é‡è¿çº¿ç¨‹ï¼Œé¿å…é˜»å¡
        for instance in instances_to_reconnect:
            logger.info(f"å¼€å§‹é‡è¿ä»»åŠ¡ï¼š{instance.name}")
            threading.Thread(
                target=self._async_reconnect_instance,
                args=(instance,),
                daemon=True,
                name=f"reconnect-{instance.name}"
            ).start()
        
    def _start_webhook_server(self) -> None:
        """å¯åŠ¨webhookæœåŠ¡å™¨"""
        try:
            self.webhook_server = WebhookServer(self, self.config)
            self.webhook_server.start()
            logger.info("WebhookæœåŠ¡å™¨å·²å¯åŠ¨")
        except Exception as e:
            logger.error(f"å¯åŠ¨webhookæœåŠ¡å™¨å¤±è´¥: {e}")
            raise
    
    def _start_api_server(self) -> None:
        """ğŸ†• å¯åŠ¨Flask APIæœåŠ¡å™¨"""
        try:
            logger.info(f"ğŸš€ æ­£åœ¨åˆå§‹åŒ–APIæœåŠ¡å™¨...")
            
            self.api_server = Flask('qb_loadbalancer_api')
            self.api_server.logger.disabled = True
            
            # ç¦ç”¨ Werkzeug æ—¥å¿—
            import logging as werkzeug_logging
            werkzeug_log = werkzeug_logging.getLogger('werkzeug')
            werkzeug_log.setLevel(werkzeug_logging.ERROR)
            
            @self.api_server.route('/api/update-ip', methods=['POST'])
            def update_ip():
                """æ¥æ”¶Hetznerç›‘æ§çš„IPå˜æ›´é€šçŸ¥"""
                try:
                    data = request.get_json()
                    if not data:
                        return jsonify({'success': False, 'error': 'No JSON data'}), 400
                    
                    new_ip = data.get('new_ip')
                    old_ip = data.get('old_ip')  # å¯é€‰
                    
                    if not new_ip:
                        return jsonify({
                            'success': False,
                            'error': 'Missing new_ip'
                        }), 400
                    
                    if old_ip:
                        logger.info(f"ğŸ“¡ æ”¶åˆ°IPå˜æ›´é€šçŸ¥: {old_ip} â†’ {new_ip}")
                    else:
                        logger.info(f"ğŸ“¡ æ”¶åˆ°æ–°IPé€šçŸ¥: {new_ip}")
                    
                    # å…ˆæ£€æŸ¥æ–°IPæ˜¯å¦å·²å­˜åœ¨
                    if self.config_manager.check_ip_exists(new_ip):
                        logger.info(f"âœ“ IP {new_ip} å·²å­˜åœ¨äºé…ç½®ä¸­ï¼Œæ— éœ€æ›´æ–°")
                        return jsonify({
                            'success': True,
                            'updated_count': 0,
                            'message': f'IP {new_ip} å·²å­˜åœ¨'
                        })
                    
                    # æ›´æ–°é…ç½®æ–‡ä»¶
                    result = self.config_manager.update_instance_ip(old_ip, new_ip)
                    
                    if result['success'] and result['updated_count'] > 0:
                        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šå…ˆæ›´æ–°å†…å­˜ä¸­çš„å®ä¾‹ï¼Œå†é‡æ–°åŠ è½½é…ç½®
                        updated_instances = []
                        with self.instances_lock:
                            for instance in self.instances:
                                current_host = self.config_manager.extract_ip_from_url(instance.url)
                                
                                # æ–¹å¼1: å¦‚æœæä¾›äº†old_ipï¼Œç²¾ç¡®åŒ¹é…æ›¿æ¢
                                if old_ip and current_host == old_ip:
                                    old_url = instance.url
                                    instance.url = instance.url.replace(old_ip, new_ip)
                                    instance.is_connected = False
                                    updated_instances.append(instance)
                                    logger.info(f"ğŸ”„ å·²æ›´æ–°å®ä¾‹ {instance.name}: {old_url} â†’ {instance.url}")
                                
                                # æ–¹å¼2: å¦‚æœæ²¡æœ‰æä¾›old_ipï¼Œæ›´æ–°ç¬¬ä¸€ä¸ªæ— æ•ˆIPçš„å®ä¾‹
                                elif not old_ip and (not current_host or not self.config_manager._is_valid_ip(current_host)):
                                    old_url = instance.url
                                    instance.url = instance.url.replace(current_host if current_host else '111', new_ip)
                                    instance.is_connected = False
                                    updated_instances.append(instance)
                                    logger.info(f"ğŸ”„ å·²æ›´æ–°å®ä¾‹ {instance.name}: {old_url} â†’ {instance.url}")
                                    break  # åªæ›´æ–°ç¬¬ä¸€ä¸ª
                        
                        # ç„¶åé‡æ–°åŠ è½½é…ç½®ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
                        self.config = self.config_manager.load_config()
                        logger.info(f"ğŸ”„ é…ç½®å·²é‡æ–°åŠ è½½")
                        
                        # å¼‚æ­¥è§¦å‘é‡è¿
                        def reconnect_instances():
                            time.sleep(1)  # ç­‰å¾…1ç§’ç¡®ä¿é…ç½®ç¨³å®š
                            for instance in updated_instances:
                                logger.info(f"ğŸ”Œ è§¦å‘å®ä¾‹é‡è¿: {instance.name}")
                                self._connect_instance(instance)
                        
                        reconnect_thread = threading.Thread(
                            target=reconnect_instances, 
                            daemon=True, 
                            name="api-reconnect"
                        )
                        reconnect_thread.start()
                        
                        logger.info(f"âœ“ IPæ›´æ–°å®Œæˆï¼Œå…±æ›´æ–° {result['updated_count']} ä¸ªå®ä¾‹")
                    
                    return jsonify(result)
                    
                except Exception as e:
                    logger.error(f"âœ— å¤„ç†IPæ›´æ–°è¯·æ±‚å¤±è´¥ï¼š{e}")
                    import traceback
                    logger.error(traceback.format_exc())
                    return jsonify({
                        'success': False,
                        'error': str(e)
                    }), 500
            
            @self.api_server.route('/health', methods=['GET'])
            def health_check():
                """å¥åº·æ£€æŸ¥æ¥å£"""
                return jsonify({
                    'status': 'ok',
                    'timestamp': datetime.now().isoformat(),
                    'instances_connected': len([i for i in self.instances if i.is_connected])
                })
            
            # åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­å¯åŠ¨APIæœåŠ¡å™¨
            def run_api():
                try:
                    logger.info(f"ğŸ“¡ APIæœåŠ¡å™¨çº¿ç¨‹å¯åŠ¨ä¸­...")
                    self.api_server.run(
                        host='0.0.0.0',
                        port=self.api_port,
                        debug=False,
                        use_reloader=False,
                        threaded=True
                    )
                except Exception as e:
                    logger.error(f"âŒ APIæœåŠ¡å™¨è¿è¡Œå¤±è´¥: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
            
            api_thread = threading.Thread(target=run_api, daemon=True, name="api-server")
            api_thread.start()
            
            # ç­‰å¾…APIæœåŠ¡å™¨å¯åŠ¨å¹¶éªŒè¯
            max_wait = 10
            for i in range(max_wait):
                time.sleep(1)
                try:
                    response = requests.get(f'http://localhost:{self.api_port}/health', timeout=2)
                    if response.status_code == 200:
                        logger.info(f"âœ… APIæœåŠ¡å™¨å¯åŠ¨æˆåŠŸå¹¶é€šè¿‡å¥åº·æ£€æŸ¥!")
                        logger.info(f"ğŸŒ ç›‘å¬åœ°å€: http://0.0.0.0:{self.api_port}")
                        logger.info(f"ğŸ“ å¯ç”¨ç«¯ç‚¹:")
                        logger.info(f"   â€¢ POST /api/update-ip - æ¥æ”¶IPå˜æ›´é€šçŸ¥")
                        logger.info(f"   â€¢ GET /health - å¥åº·æ£€æŸ¥")
                        return
                except:
                    if i < max_wait - 1:
                        logger.debug(f"ç­‰å¾…APIæœåŠ¡å™¨å°±ç»ª... ({i+1}/{max_wait})")
                    pass
            
            logger.warning(f"âš ï¸ APIæœåŠ¡å™¨å¯èƒ½æœªå®Œå…¨å¯åŠ¨ï¼Œä½†è¿›ç¨‹å·²è¿è¡Œ")
            logger.info(f"ğŸŒ ç›‘å¬åœ°å€: http://0.0.0.0:{self.api_port}")
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨APIæœåŠ¡å™¨å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def add_pending_torrent(self, download_url: str, release_name: str, category: Optional[str] = None) -> None:
        """æ·»åŠ å¾…å¤„ç†çš„torrent"""
        if not download_url:
            logger.error("å¿…é¡»æä¾›download_url")
            return
            
        if not release_name:
            logger.error("å¿…é¡»æä¾›release_name")
            return
        
        try:
            with self.pending_torrents_lock:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆä½¿ç”¨URLä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼‰
                exists = any(t.download_url == download_url for t in self.pending_torrents)
                
                if not exists:
                    torrent = PendingTorrent(
                        download_url=download_url,
                        release_name=release_name,
                        category=category
                    )
                    self.pending_torrents.append(torrent)
                    logger.info(f"æ·»åŠ å¾…å¤„ç†ç§å­ï¼š{release_name}")
                else:
                    logger.debug(f"ç§å­å·²åœ¨å¾…å¤„ç†åˆ—è¡¨ä¸­ï¼š{release_name}")
                    
        except Exception as e:
            logger.error(f"æ·»åŠ ç§å­å¤±è´¥ï¼š{release_name}ï¼Œé”™è¯¯ï¼š{e}")
            

                
    def _update_instance_status(self) -> None:
        """æ›´æ–°æ‰€æœ‰å®ä¾‹çš„çŠ¶æ€ä¿¡æ¯"""
        with self.instances_lock:
            for instance in self.instances:
                if instance.is_connected:
                    self._update_single_instance(instance)
                    
    def _update_single_instance(self, instance: InstanceInfo) -> None:
        """æ›´æ–°å•ä¸ªå®ä¾‹çš„çŠ¶æ€ä¿¡æ¯"""
        def _try_update_instance():
            """å°è¯•æ›´æ–°å®ä¾‹çŠ¶æ€çš„å†…éƒ¨å‡½æ•°"""
            maindata = instance.client.sync_maindata()
            self._update_instance_metrics(instance, maindata)
            self._process_instance_announces(instance, maindata)
        
        # ç¬¬ä¸€æ¬¡å°è¯•
        try:
            _try_update_instance()
            return
        except Exception as e:
            logger.warning(f"æ›´æ–°å®ä¾‹çŠ¶æ€å¤±è´¥ï¼š{instance.name}ï¼Œé”™è¯¯ï¼š{e}ï¼Œç­‰å¾…5ç§’åé‡è¯•")
            time.sleep(5)
        
        # ç¬¬äºŒæ¬¡å°è¯•
        try:
            _try_update_instance()
            logger.info(f"å®ä¾‹ {instance.name} é‡è¯•æˆåŠŸ")
        except Exception as e2:
            logger.error(f"é‡è¯•åä»ç„¶å¤±è´¥ï¼š{instance.name}ï¼Œé”™è¯¯ï¼š{e2}ï¼Œæ ‡è®°ä¸ºæ–­å¼€è¿æ¥")
            instance.is_connected = False
            instance.last_update = datetime.now()
                    
    def _update_instance_metrics(self, instance: InstanceInfo, maindata: dict) -> None:
        """ä½¿ç”¨sync/maindataçš„ç»“æœæ›´æ–°å•ä¸ªå®ä¾‹çš„çŠ¶æ€ä¿¡æ¯"""
        server_state = maindata.get('server_state', {})
        
        # ä»server_stateè·å–å…¨å±€ç»Ÿè®¡ä¿¡æ¯å’Œç¡¬ç›˜ç©ºé—´
        instance.upload_speed = server_state.get('up_info_speed', 0) / BYTES_TO_KB
        instance.download_speed = server_state.get('dl_info_speed', 0) / BYTES_TO_KB
        instance.free_space = server_state.get('free_space_on_disk', 0)
        
        # ä»torrentsä¿¡æ¯è®¡ç®—æ´»è·ƒä¸‹è½½æ•°
        all_torrents = maindata.get('torrents', {}).values()
        instance.active_downloads = len([t for t in all_torrents if t.state == 'downloading'])
        
        instance.last_update = datetime.now()
        instance.success_metrics_count += 1  # æˆåŠŸè·å–ç»Ÿè®¡ä¿¡æ¯ï¼Œè®¡æ•°å™¨åŠ 1
        
        # æ¯30æ¬¡æˆåŠŸæ›´æ–°æ—¶æ£€æŸ¥ä¸€æ¬¡æµé‡ä¿¡æ¯
        if instance.success_metrics_count % 30 == 0:
            self._check_instance_traffic(instance)
        
        logger.debug(f"å®ä¾‹ {instance.name}ï¼š" 
                   f"ä¸Šä¼ ={instance.upload_speed:.1f}KB/sï¼Œ"
                   f"ä¸‹è½½={instance.download_speed:.1f}KB/sï¼Œ"
                   f"æ´»è·ƒä¸‹è½½={instance.active_downloads}ï¼Œ"
                   f"ç©ºé—´={instance.free_space/BYTES_TO_GB:.1f}/{instance.reserved_space/BYTES_TO_GB:.1f}GBï¼Œ"
                   f"æ›´æ–°={instance.success_metrics_count}ï¼Œ"
                   f"å†å²ä»»åŠ¡={instance.total_added_tasks_count}")


    def _check_instance_traffic(self, instance: InstanceInfo) -> None:
        """æ£€æŸ¥å®ä¾‹çš„æµé‡ä¿¡æ¯"""
        if not instance.traffic_check_url:
            return
            
        try:
            response = requests.get(instance.traffic_check_url, timeout=5)
            response.raise_for_status()
            traffic_data = response.json()
            
            # è·å–å‡ºç«™æµé‡ï¼Œä»MBè½¬æ¢ä¸ºå­—èŠ‚
            try:
                traffic_out_mb = traffic_data.get('out', 0.0)
                instance.traffic_out = int(float(traffic_out_mb) * 1024 * 1024)  # MBè½¬å­—èŠ‚
                
                # æ£€æŸ¥æ˜¯å¦æµé‡è¢«é™æµ
                traffic_throttled = traffic_data.get('trafficThrottled', False)
                if traffic_throttled:
                    instance.traffic_out = 9999 * BYTES_TO_TB  # è®¾ç½®ä¸ºæå¤§å€¼ï¼Œç¡®ä¿åœ¨æµé‡æ£€æŸ¥æ—¶è¢«è¿‡æ»¤
                    logger.warning(f"å®ä¾‹ {instance.name} æµé‡è¢«é™æµï¼Œè®¾ç½®æµé‡ä¸ºæå¤§å€¼ä»¥é¿å…è¢«é€‰æ‹©")
                    
            except (ValueError, TypeError) as e:
                logger.warning(f"å®ä¾‹ {instance.name} æµé‡æ•°æ®è½¬æ¢å¤±è´¥ï¼š{e}ï¼Œè®¾ç½®ä¸º0")
                instance.traffic_out = 0
            
            logger.debug(f"æ›´æ–°å®ä¾‹ {instance.name} æµé‡ä¿¡æ¯ï¼šå‡ºç«™æµé‡={instance.traffic_out/BYTES_TO_GB:.2f}GBï¼Œé™åˆ¶={instance.traffic_limit/BYTES_TO_GB:.2f}GB")
            
        except Exception as e:
            logger.warning(f"è·å–å®ä¾‹ {instance.name} æµé‡ä¿¡æ¯å¤±è´¥ï¼š{e}")
            instance.traffic_out = 0
    
    def _is_traffic_within_limit(self, instance: InstanceInfo) -> bool:
        """æ£€æŸ¥å®ä¾‹çš„æµé‡æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…"""
        # å¦‚æœå‡ºç«™æµé‡ä¸º0ï¼ˆæœªæ£€æŸ¥æˆ–æ£€æŸ¥å¤±è´¥ï¼‰ï¼Œè®¤ä¸ºæµé‡æœªè¶…å‡º
        if instance.traffic_out == 0:
            return True
        
        # å¦‚æœæ²¡æœ‰è®¾ç½®æµé‡é™åˆ¶ï¼Œè®¤ä¸ºæµé‡æœªè¶…å‡º
        if instance.traffic_limit == 0:
            return True
            
        # æ¯”è¾ƒå‡ºç«™æµé‡å’Œæµé‡é™åˆ¶
        within_limit = instance.traffic_out < instance.traffic_limit
        
        if not within_limit:
            logger.warning(f"å®ä¾‹ {instance.name} æµé‡è¶…é™ï¼šå‡ºç«™æµé‡={instance.traffic_out/BYTES_TO_GB:.2f}GBï¼Œé™åˆ¶={instance.traffic_limit/BYTES_TO_GB:.2f}GB")
        
        return within_limit
                   
    def _process_instance_announces(self, instance: InstanceInfo, maindata: dict) -> None:
        """å¤„ç†å®ä¾‹çš„ç§å­æ±‡æŠ¥æ£€æŸ¥"""
        # å¦‚æœdebug_add_stoppedä¸ºTrueï¼Œç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•å¤„ç†
        if self.config.get('debug_add_stopped', False):
            return
            
        # å¦‚æœå¿«é€Ÿæ±‡æŠ¥å¼€å…³æœªå¯ç”¨ï¼Œç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•å¤„ç†
        if not self.config.get('fast_announce_enabled', False):
            return

        max_retries = self.config.get('max_announce_retries', 12)
        error_keywords = ["unregistered", "not registered", "not found", "not exist"]
        current_time = datetime.now()

        all_torrents_items = maindata.get('torrents', {}).items()

        for torrent_hash, torrent in all_torrents_items:
            age_seconds = (current_time - datetime.fromtimestamp(torrent.added_on)).total_seconds()
            is_completed = torrent.progress == 1.0

            # æ¡ä»¶1ï¼šå¦‚æœç§å­å·²å®Œæˆæˆ–æ·»åŠ è¶…è¿‡2åˆ†é’Ÿï¼Œåˆ™ç¡®ä¿å…¶å·²ä»ç›‘æ§åˆ—è¡¨ä¸­ç§»é™¤ï¼Œå¹¶è·³è¿‡
            if (is_completed and age_seconds > 60) or age_seconds > 140 or age_seconds < 2:
                if torrent_hash in self.announce_retry_counts:
                    del self.announce_retry_counts[torrent_hash]
                    if is_completed:
                        reason = "å·²å®Œæˆ"
                    elif age_seconds > 120:
                        reason = "è¶…è¿‡2åˆ†é’Ÿ"
                    else:
                        reason = "æ·»åŠ æ—¶é—´å°äº2ç§’"
                    logger.debug(f"åœæ­¢æ±‡æŠ¥ç›‘æ§: {torrent.name} (åŸå› : {reason})")
                continue
                
            # æ£€æŸ¥ç§å­åˆ†ç±»æ˜¯å¦åœ¨å¿«é€Ÿæ±‡æŠ¥é»‘åå•ä¸­
            blacklist = self.config.get('fast_announce_category_blacklist', [])
            if blacklist and hasattr(torrent, 'category') and torrent.category in blacklist:
                # å¦‚æœç§å­åˆ†ç±»åœ¨é»‘åå•ä¸­ï¼Œä»ç›‘æ§åˆ—è¡¨ä¸­ç§»é™¤å¹¶è·³è¿‡
                if torrent_hash in self.announce_retry_counts:
                    del self.announce_retry_counts[torrent_hash]
                    logger.debug(f"è·³è¿‡å¿«é€Ÿæ±‡æŠ¥: {torrent.name} (åˆ†ç±» '{torrent.category}' åœ¨é»‘åå•ä¸­)")
                continue
                
            # æ¡ä»¶2ï¼šå¦‚æœç§å­æœªå®Œæˆä¸”æœªè¶…è¿‡2åˆ†é’Ÿï¼Œåˆ™è¿›è¡Œæ±‡æŠ¥æ£€æŸ¥
            # åˆå§‹åŒ–æˆ–é€’å¢é‡è¯•è®¡æ•°å™¨
            if torrent_hash not in self.announce_retry_counts:
                self.announce_retry_counts[torrent_hash] = 0
            
            # æ¯æ¬¡è¿›å…¥å‡½æ•°æ—¶é€’å¢è®¡æ•°å™¨
            self.announce_retry_counts[torrent_hash] += 1
            current_retries = self.announce_retry_counts[torrent_hash]
            
            logger.debug(f"æ±‡æŠ¥æ£€æŸ¥: {torrent.name} (ç¬¬{current_retries}æ¬¡æ£€æŸ¥ï¼Œæœ€å¤§{max_retries}æ¬¡)")

            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°1åˆ†é’Ÿæˆ–è€…2åˆ†é’Ÿä¸”ç§å­ä»æœªå®Œæˆï¼Œå¦‚æœæ˜¯åˆ™å¼ºåˆ¶æ±‡æŠ¥
            fast_interval = self.config.get('fast_announce_interval', 3)
            first_force_announce = int(60 / fast_interval)
            second_force_announce = int(120 / fast_interval)
            if (current_retries == first_force_announce or current_retries == second_force_announce) and not is_completed:
                logger.info(f"è¾¾åˆ°ç‰¹å®šæ¬¡æ•°({current_retries})ä¸”ç§å­æœªå®Œæˆï¼Œå¼ºåˆ¶æ±‡æŠ¥: {torrent.name}")
                self._announce_torrent(instance, torrent, torrent_hash, f"å¼ºåˆ¶æ±‡æŠ¥(ç¬¬{current_retries}æ¬¡æ£€æŸ¥)")
                continue

            # å¦‚æœè¿˜æ²¡åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç»§ç»­æ­£å¸¸çš„æ±‡æŠ¥æ¡ä»¶æ£€æŸ¥
            if current_retries < max_retries:
                # æ£€æŸ¥æ±‡æŠ¥æ¡ä»¶
                needs_announce = False
                reason = []

                try:
                    # 1. æ£€æŸ¥TrackerçŠ¶æ€
                    trackers = instance.client.torrents_trackers(torrent_hash=torrent_hash)
                    
                    # Filter out non-HTTP trackers and special trackers like DHT, PEX, LSD
                    filtered_trackers = []
                    for t in trackers:
                        if t.url.lower() in ('dht', 'pex', 'lsd'):
                            continue
                        if not t.url.startswith(('http://', 'https://')):
                            continue
                        filtered_trackers.append(t)

                    if not filtered_trackers:
                        logger.info(f"[{instance.name}] Announce check for '{torrent.name}': No valid HTTP trackers found, skipping.")
                        continue

                    all_trackers_failed = all(t.status in [1, 3, 4] for t in filtered_trackers)
                    has_error_keyword = any(keyword in t.msg.lower() for t in filtered_trackers for keyword in error_keywords)

                    if all_trackers_failed:
                        needs_announce = True
                        reason.append("æ‰€æœ‰trackerçŠ¶æ€å¼‚å¸¸")
                    if has_error_keyword:
                        needs_announce = True
                        reason.append("å‘ç°trackeré”™è¯¯ä¿¡æ¯")

                    # 2. æ£€æŸ¥Peeræ•°é‡
                    if torrent.progress < 0.8 and torrent.num_leechs < 2:
                        needs_announce = True
                        reason.append(f"Peeræ•°é‡ä¸è¶³({torrent.num_leechs})")

                    # æ‰§è¡Œæ±‡æŠ¥
                    if needs_announce:
                        self._announce_torrent(instance, torrent, torrent_hash, ", ".join(reason))

                except Exception as e:
                    logger.warning(f"å¤„ç† {torrent.name} çš„æ±‡æŠ¥æ—¶å‡ºé”™: {e}")

    def _announce_torrent(self, instance: InstanceInfo, torrent: any, torrent_hash: str, reason: str) -> None:
        """å¯¹å•ä¸ªç§å­æ‰§è¡Œannounce"""
        try:
            instance.client.torrents_reannounce(torrent_hashes=torrent_hash)
            current_retries = self.announce_retry_counts.get(torrent_hash, 0)
            logger.info(f"è§¦å‘æ±‡æŠ¥: {torrent.name} (åŸå› : {reason}) | "
                        f"å°è¯•æ¬¡æ•°: {current_retries}")
        except Exception as e:
            logger.warning(f"æ±‡æŠ¥å¤±è´¥: {torrent.name}ï¼Œé”™è¯¯: {e}")


    def _get_primary_sort_value(self, instance: InstanceInfo) -> float:
        """è·å–ä¸»è¦æ’åºå› ç´ çš„å€¼"""
        primary_sort_key = self.config.get('primary_sort_key', DEFAULT_PRIMARY_SORT_KEY)
        
        if primary_sort_key == 'upload_speed':
            return instance.upload_speed
        elif primary_sort_key == 'download_speed':
            return instance.download_speed
        elif primary_sort_key == 'active_downloads':
            return float(instance.active_downloads)
        else:
            # é»˜è®¤ä½¿ç”¨ä¸Šä¼ é€Ÿåº¦
            return instance.upload_speed
        
    def _select_best_instance(self) -> Optional[InstanceInfo]:
        """é€‰æ‹©æœ€ä½³çš„å®ä¾‹æ¥åˆ†é…æ–°ä»»åŠ¡"""
        with self.instances_lock:
            available_instances = [
                instance for instance in self.instances 
                if instance.is_connected and 
                instance.new_tasks_count < self.config['max_new_tasks_per_instance'] and
                instance.free_space > instance.reserved_space and
                self._is_traffic_within_limit(instance)
            ]
            
            if not available_instances:
                return None
                
            # æŒ‰å¯é…ç½®ç®—æ³•æ’åºï¼šä¸»è¦å› ç´ ï¼ˆå°å€¼ä¼˜å…ˆï¼‰ï¼Œæ¬¡è¦å› ç´ æ˜¯ä»»åŠ¡è®¡æ•°ï¼ˆå°å€¼ä¼˜å…ˆï¼‰ï¼Œç¬¬ä¸‰å› ç´ æ˜¯ç¡¬ç›˜ç©ºé—´ï¼ˆå¤§å€¼ä¼˜å…ˆï¼‰
            available_instances.sort(key=lambda x: (
                self._get_primary_sort_value(x),  # ä¸»è¦å› ç´ ï¼šå°å€¼ä¼˜å…ˆ
                x.total_added_tasks_count,        # æ¬¡è¦å› ç´ ï¼šå·²æ·»åŠ ä»»åŠ¡è®¡æ•°å°çš„ä¼˜å…ˆ
                -x.free_space                     # ç¬¬ä¸‰å› ç´ ï¼šç¡¬ç›˜ç©ºé—´å¤§çš„ä¼˜å…ˆï¼ˆä½¿ç”¨è´Ÿå·ï¼‰
            ))
            
            selected = available_instances[0]
            primary_sort_key = self.config.get('primary_sort_key', DEFAULT_PRIMARY_SORT_KEY)
            primary_value = self._get_primary_sort_value(selected)
            
            logger.debug(f"é€‰æ‹©å®ä¾‹ {selected.name}ï¼š" 
                        f"{SUPPORTED_SORT_KEYS[primary_sort_key]}={primary_value:.1f}ï¼Œ"
                        f"å·²æ·»åŠ ä»»åŠ¡æ•°={selected.total_added_tasks_count}ï¼Œ"
                        f"ç©ºé—²ç©ºé—´={selected.free_space/BYTES_TO_GB:.1f}GBï¼Œ"
                        f"ä¿ç•™ç©ºé—´={selected.reserved_space/BYTES_TO_GB:.1f}GBï¼Œ"
                        f"æµé‡={selected.traffic_out/BYTES_TO_GB:.2f}/{selected.traffic_limit/BYTES_TO_GB:.2f}GB")
            
            return selected
            
    def _add_torrent_to_instance(self, instance: InstanceInfo, torrent: PendingTorrent) -> bool:
        """å°†torrentæ·»åŠ åˆ°æŒ‡å®šå®ä¾‹"""
        try:
            add_params = {'urls': torrent.download_url}
            
            # è®¾ç½®åˆ†ç±»
            if torrent.category:
                add_params['category'] = torrent.category
                logger.info(f"ä¸ºç§å­è®¾ç½®åˆ†ç±»ï¼š{torrent.release_name} -> {torrent.category}")
                
            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å°†ç§å­æ·»åŠ ä¸ºæš‚åœçŠ¶æ€ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            if self.config.get('debug_add_stopped', False):
                add_params['is_stopped'] = True
                logger.info(f"è°ƒè¯•æ¨¡å¼ï¼šç§å­å°†ä»¥æš‚åœçŠ¶æ€æ·»åŠ  - {torrent.release_name}")

            result = instance.client.torrents_add(**add_params)
            
            if result and result.startswith('Ok'):
                instance.new_tasks_count += 1
                instance.total_added_tasks_count += 1  # å¢åŠ ç´¯è®¡ä»»åŠ¡è®¡æ•°
                log_msg = f"æˆåŠŸæ·»åŠ ç§å­åˆ°å®ä¾‹ {instance.name}ï¼š{torrent.release_name}"
                if torrent.category:
                    log_msg += f"ï¼ˆåˆ†ç±»ï¼š{torrent.category}ï¼‰"
                logger.info(log_msg)
                return True
            else:
                logger.error(f"æ·»åŠ ç§å­å¤±è´¥ - å®ä¾‹ï¼š{instance.name}ï¼Œç§å­ï¼š{torrent.release_name}ï¼Œç»“æœï¼š{result}")
                return False
                
        except Exception as e:
            logger.error(f"æ·»åŠ ç§å­åˆ°å®ä¾‹å¤±è´¥ - å®ä¾‹ï¼š{instance.name}ï¼Œç§å­ï¼š{torrent.release_name}ï¼Œé”™è¯¯ï¼š{e}")
            return False
            
    def _process_torrents(self) -> None:
        """å¤„ç†å¾…åˆ†é…çš„torrent URL"""
        with self.pending_torrents_lock:
            if not self.pending_torrents:
                return
                
            # å¤„ç†æ‰€æœ‰å¾…å¤„ç†çš„torrent URL
            for torrent in self.pending_torrents[:]:  # ä½¿ç”¨åˆ‡ç‰‡é¿å…ä¿®æ”¹åˆ—è¡¨æ—¶çš„é—®é¢˜
                instance = self._select_best_instance()
                if instance:
                    if self._add_torrent_to_instance(instance, torrent):
                        self.pending_torrents.remove(torrent)
                else:
                    logger.warning("æ²¡æœ‰å¯ç”¨çš„å®ä¾‹æ¥åˆ†é…æ–°ä»»åŠ¡ï¼Œæ¸…ç©ºå¾…å¤„ç†é˜Ÿåˆ—")
                    self.pending_torrents.clear()
                    break

    def _reset_task_counters(self) -> None:
        """é‡ç½®ä»»åŠ¡è®¡æ•°å™¨ï¼ˆæ¯è½®å¤„ç†å®Œæˆåï¼‰"""
        with self.instances_lock:
            for instance in self.instances:
                instance.new_tasks_count = 0
                
    def _log_status_summary(self) -> None:
        """è®°å½•çŠ¶æ€æ‘˜è¦ä¿¡æ¯"""
        with self.instances_lock:
            total_instances = len(self.instances)
            connected_count = sum(1 for i in self.instances if i.is_connected)
            disconnected_instances = [i.name for i in self.instances if not i.is_connected]
            
            status_msg = f"å®ä¾‹çŠ¶æ€: {connected_count}/{total_instances} è¿æ¥æ­£å¸¸"
            if disconnected_instances:
                status_msg += f", æ–­å¼€è¿æ¥: {', '.join(disconnected_instances)}"
            
            logger.debug(status_msg)
                
    def status_update_thread(self) -> None:
        """çŠ¶æ€æ›´æ–°çº¿ç¨‹"""
        # ç­‰å¾…åˆå§‹è¿æ¥å®Œæˆï¼ˆæœ€å¤š10ç§’ï¼‰
        logger.info("â³ ç­‰å¾…å®ä¾‹åˆå§‹åŒ–...")
        for i in range(10):
            time.sleep(1)
            with self.instances_lock:
                connected = sum(1 for inst in self.instances if inst.is_connected)
                if connected > 0:
                    logger.info(f"âœ“ å·²è¿æ¥ {connected}/{len(self.instances)} ä¸ªå®ä¾‹")
                    break
        
        logger.info("ğŸ”„ çŠ¶æ€ç›‘æ§çº¿ç¨‹å¼€å§‹è¿è¡Œ")
        
        while True:
            try:
                self._update_instance_status()
                self._log_status_summary()
                self._check_and_schedule_reconnects()
                              
                # æ ¹æ®æ˜¯å¦æœ‰å¾…é‡è¯•çš„æ±‡æŠ¥ä»»åŠ¡æ¥è°ƒæ•´æ£€æŸ¥é¢‘ç‡
                fast_interval = self.config['fast_announce_interval']
                if self.announce_retry_counts:
                    time.sleep(fast_interval)  # æœ‰å¾…é‡è¯•ä»»åŠ¡æ—¶çš„å¿«é€Ÿæ£€æŸ¥é¢‘ç‡
                else:
                    time.sleep(fast_interval * 2)  # æ­£å¸¸æƒ…å†µä¸‹çš„æ£€æŸ¥é¢‘ç‡
                
            except Exception as e:
                logger.error(f"çŠ¶æ€æ›´æ–°çº¿ç¨‹é”™è¯¯ï¼š{e}")
                time.sleep(ERROR_RETRY_SLEEP)
                
    def task_processor_thread(self) -> None:
        """ä»»åŠ¡å¤„ç†çº¿ç¨‹"""
        logger.info("ğŸ“¦ ä»»åŠ¡å¤„ç†çº¿ç¨‹å¼€å§‹è¿è¡Œ")
        
        while True:
            try:
                # è®°å½•å½“å‰å¾…å¤„ç†çš„ç§å­æ•°é‡ï¼ˆæ›´åŠæ—¶çš„ä¿¡æ¯ï¼‰
                with self.pending_torrents_lock:
                    pending_count = len(self.pending_torrents)
                
                if pending_count > 0:
                    logger.debug(f"å¤„ç† {pending_count} ä¸ªå¾…åˆ†é…çš„ç§å­")
                
                self._process_torrents()
                self._reset_task_counters()
                time.sleep(TASK_PROCESSOR_SLEEP)
                
            except Exception as e:
                logger.error(f"ä»»åŠ¡å¤„ç†çº¿ç¨‹é”™è¯¯ï¼š{e}")
                time.sleep(ERROR_RETRY_SLEEP)
                
    def run(self) -> None:
        """è¿è¡Œè´Ÿè½½å‡è¡¡å™¨"""
        logger.info("="*70)
        logger.info("  qBittorrent è´Ÿè½½å‡è¡¡å™¨å¯åŠ¨")
        logger.info("="*70)
        
        # æ˜¾ç¤ºé…ç½®æ‘˜è¦
        logger.info(f"ğŸ“‹ é…ç½®æ‘˜è¦:")
        logger.info(f"   â€¢ å®ä¾‹æ•°é‡: {len(self.instances)}")
        logger.info(f"   â€¢ Webhookç«¯å£: {self.config.get('webhook_port', 5000)}")
        logger.info(f"   â€¢ APIç«¯å£: {self.api_port}")
        logger.info(f"   â€¢ æ—¥å¿—ç›®å½•: {self.config.get('log_dir', './logs')}")

        self.config_watcher.start()
        
        # å¯åŠ¨çŠ¶æ€æ›´æ–°çº¿ç¨‹
        status_thread = threading.Thread(target=self.status_update_thread, daemon=True)
        status_thread.start()
        logger.info("âœ“ çŠ¶æ€æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨")

        # å¯åŠ¨çŠ¶æ€æ›´æ–°çº¿ç¨‹
        status_thread = threading.Thread(target=self.status_update_thread, daemon=True)
        status_thread.start()
        logger.info("âœ“ çŠ¶æ€æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨")
        
        # å¯åŠ¨ä»»åŠ¡å¤„ç†çº¿ç¨‹
        task_thread = threading.Thread(target=self.task_processor_thread, daemon=True)
        task_thread.start()
        logger.info("âœ“ ä»»åŠ¡å¤„ç†çº¿ç¨‹å·²å¯åŠ¨")
        
        logger.info("="*70)
        logger.info("ğŸš€ æ‰€æœ‰æœåŠ¡å·²å¯åŠ¨ï¼Œç³»ç»Ÿè¿è¡Œä¸­...")
        logger.info("ğŸ’¡ æç¤º: ä½¿ç”¨ Ctrl+C åœæ­¢ç¨‹åº")
        logger.info("="*70)
        
        try:
            # ä¸»çº¿ç¨‹ä¿æŒè¿è¡Œ
            while True:
                time.sleep(DEFAULT_SLEEP_TIME)
        except KeyboardInterrupt:
            logger.info("\n" + "="*70)
            logger.info("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
            logger.info("="*70)
            
            # ğŸ†• åœæ­¢é…ç½®ç›‘æ§
            if self.config_watcher:
                self.config_watcher.stop()
                logger.info("âœ“ é…ç½®ç›‘æ§å·²åœæ­¢")
            
            if self.webhook_server:
                self.webhook_server.stop()
                logger.info("âœ“ WebhookæœåŠ¡å™¨å·²åœæ­¢")
            
            logger.info("âœ“ ç¨‹åºå·²å®‰å…¨é€€å‡º")


def main() -> int:
    """ä¸»å‡½æ•°"""
    try:
        balancer = QBittorrentLoadBalancer()
        balancer.run()
        return 0
    except Exception as e:
        logger.error(f"ç¨‹åºå¯åŠ¨å¤±è´¥ï¼š{e}")
        return 1


if __name__ == "__main__":
    exit(main())